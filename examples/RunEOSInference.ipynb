{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "To run eosinference, you will have to install the following dependencies:\n",
    " * pandas: `pip install --user pandas`\n",
    " * h5py: `pip install --user h5py`\n",
    " * emcee (I used version 2.2.1): `pip install --user emcee`\n",
    " * corner: `pip install --user corner`\n",
    " * lalsuite: I'm sorry you have to install this.\n",
    "\n",
    "\n",
    "## Estimating EOS parameters and NS properties from multiple BNS events\n",
    "\n",
    "This tutorial demonstrates how to sample EOS parameters from BNS data. The input is a set of MCMC runs for each BNS event. The code make the assumption that the MCMC runs were done using priors in 'q' and 'lambdat' that were flat (uniform). If the priors were not flot to begin with, you must reweight the posterior in such a way that the reweighted samples correspond to a flat prior.\n",
    "\n",
    "You will have to run 4 scripts to produce a final plots and output page.\n",
    "1. `generate_likelihood.py`: This evaluates the quantity $\\ln(p(q, \\tilde\\Lambda))$ on a grid using a bounded 2d KDE from the samples for $(q, \\tilde\\Lambda)$. This is the log(marginalized posterior). Because it is assumed that the prior in $(q, \\tilde\\Lambda)$ is flat, this just becomes a pseudo-likelihood for each BNS event. Because the uncertainty in chirp mass $\\mathcal{M}$ is so small, the chirp mass for each event is taken to be the mean value.\n",
    " * `--pefiles` The MCMC runs in CSV format. The column headers must contain ('mc', 'q', 'lambdat').\n",
    " * `--outfile` Name of the hdf5 file for the gridded likelihood function for each BNS. Also stores the mean chirpmass of each BNS.\n",
    " * `--qmin`, `--lambdatmax` The likelihood is approximated from the MCMC samples with a bounded_2d_kde it's boundaries are ((qmin, 1), (0, lambdatmax)). You must make sure that no samples extend beyond these boundaries. Otherwise, the KDE method will not work correctly.\n",
    " * `--gridsize` The KDE approximation of the likelihood is gridded up. This is the number of grid points in each dimension (q, lambdat).\n",
    "\n",
    "2. `sample_distribution.py`: This script runs the sampler `emcee` on either the prior or the posterior for the N BNS events. \n",
    " * `--infile` The data file `pseudolikelihood.hdf5` that contains the chirp mass and gridded pseudolikelihoods for each BNS event.\n",
    " * `--outfile` Output of `emcee` in hdf5 format. Contains the chir masses, ln(posterior) and chains for each walker.\n",
    " * `--distribution` Either prior on posterior \n",
    " * `--nwalkers` Number of walkers for `emcee` must be atleast twice the number of sampled parameters >2*(N_BNS+N_EOS). The more the merrier. 64 works well.\n",
    " * `--niter`  \n",
    " * `--nthin` Thin the final output to reduce file size of outfile.\n",
    " * `--massknown` Highest known NS mass. This is used to place a minimum bound on the maximum mass for the prior.\n",
    " * `--vsmax` Cutoff for maximum allowed speed of sound\n",
    " * `--qmin` Minimum allowed mass ratio for the prior. This doesn't have to be the same as the value used to generate the 2d_bounded_kde in `generate_likelihood.py`.\n",
    " * `--mmin` Minimum allowed individual NS mass for the prior.\n",
    " * `--mmax` Maximum allowed individual NS mass for the prior.\n",
    " \n",
    " \n",
    "3. `calculate_ns_properties.py`: Once the mass ratios and EOS parameters are sampled for both the prior and posterior, this script calculates the following NS properties (for both the prior and posterior):\n",
    " * Maximum mass for each EOS sample.\n",
    " * Radius as a function of mass for each EOS sample.\n",
    " * $\\Lambda$ as a function of mass for each EOS sample.\n",
    " * Samples for (mass1, mass2, radius1, radius2, lambda1, lambda2) for each of the N BNS events. These are derived from the sampled values of $\\mathcal{M}$, $q$ and the EOS parameters. \n",
    " \n",
    " * `--priorfile` \n",
    " * `--posteriorfile` \n",
    " * `--outfile` \n",
    " * `--nburnin` Number of samples to remove from the prior and posterior files for burnin. \n",
    " * `--nthin` Thin the data in the files. If you have already thinned the samples in `sample_distribution.py`, this will reduce the samples by another factor.\n",
    " * `--nsample` The final number of samples to use for calculating NS properties. If you set it to a really high value, it will use the maximum number of available samples available after removing burnin and thinning.\n",
    " \n",
    "4. `generate_eos_output_page.py`: This script generates the final plots for the page `eos_output_page.html`.\n",
    " * `--infile` The ns_properties hdf5 file.\n",
    " * `--outdir` Directory to output the final plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing radius--mass results for GW170817\n",
    "\n",
    "Using samples for GW170817 with flat priors in $(q, \\tilde\\Lambda)$, These commands should reproduce the results for GW170817 found in [arXiv:1805.11581](https://arxiv.org/abs/1805.11581). The only difference is the choice of EOS parameterization.\n",
    "\n",
    "If you just want to see some rough output in 5 minutes, try these parameters:\n",
    "```\n",
    "NITER=100\n",
    "NBURNIN=20\n",
    "NTHIN=5\n",
    "NSAMPLE=1000\n",
    "```\n",
    "\n",
    "If you want accurate results, try these parameters (1-2 hours):\n",
    "```\n",
    "NITER=1000\n",
    "NBURNIN=200\n",
    "NTHIN=10\n",
    "NSAMPLE=5000\n",
    "```\n",
    "\n",
    "To really make sure you have properly converged chains and you are outside burnin, try 10,000 iterations (~1 day):\n",
    "```\n",
    "NITER=10000\n",
    "NBURNIN=5000\n",
    "NTHIN=10\n",
    "NSAMPLE=10000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# MCMC runs for each BNS system\n",
    "PEDATA0=\"RR30_reweight.csv\"\n",
    "\n",
    "# Output directory\n",
    "OUTDIR=\"gw170817output\"\n",
    "\n",
    "# Sampling parameters\n",
    "NITER=1000\n",
    "NWALKERS=64\n",
    "NBURNIN=200\n",
    "NTHIN=10\n",
    "NSAMPLE=5000\n",
    "\n",
    "####### Start eosinference ########\n",
    "\n",
    "# Create an output directory\n",
    "mkdir $OUTDIR\n",
    "\n",
    "# Generate pseudolikelihood function ln(p)(q, lambdat) for each BNS event\n",
    "python ../bin/generate_likelihood.py \\\n",
    "--pefiles $PEDATA0 \\\n",
    "--outfile ${OUTDIR}/pseudolikelihood.hdf5 \\\n",
    "--qmin 0.125 --lambdatmax 10000 --gridsize 250\n",
    "\n",
    "# Sample the prior\n",
    "python ../bin/sample_distribution.py \\\n",
    "--infile ${OUTDIR}/pseudolikelihood.hdf5 \\\n",
    "--outfile ${OUTDIR}/prior.hdf5 \\\n",
    "--distribution prior \\\n",
    "--nwalkers $NWALKERS --niter $NITER --nthin 1 \\\n",
    "--massknown 1.93 --vsmax 1.1 --qmin 0.125 --mmin 0.5 --mmax 3.2\n",
    "\n",
    "# Sample the posterior\n",
    "python ../bin/sample_distribution.py \\\n",
    "--infile ${OUTDIR}/pseudolikelihood.hdf5 \\\n",
    "--outfile ${OUTDIR}/posterior.hdf5 \\\n",
    "--distribution posterior \\\n",
    "--nwalkers $NWALKERS --niter $NITER --nthin 1 \\\n",
    "--massknown 1.93 --vsmax 1.1 --qmin 0.125 --mmin 0.5 --mmax 3.2\n",
    "\n",
    "# Run the postprocessing script\n",
    "python ../bin/calculate_ns_properties.py \\\n",
    "--priorfile ${OUTDIR}/prior.hdf5 \\\n",
    "--posteriorfile ${OUTDIR}/posterior.hdf5 \\\n",
    "--outfile ${OUTDIR}/ns_properties.hdf5 \\\n",
    "--nburnin $NBURNIN --nthin $NTHIN --nsample $NSAMPLE\n",
    "\n",
    "# Generate output html page\n",
    "python ../bin/generate_eos_output_page.py \\\n",
    "--infile ${OUTDIR}/ns_properties.hdf5 \\\n",
    "--outdir ${OUTDIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using MCMC runs from 3 BNS events\n",
    "\n",
    "This just uses 3 copies of the GW170817 MCMC files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# MCMC runs for each BNS system\n",
    "PEDATA0=\"RR30_reweight.csv\"\n",
    "PEDATA1=\"RR30_reweight.csv\"\n",
    "PEDATA2=\"RR30_reweight.csv\"\n",
    "\n",
    "# Output directory\n",
    "OUTDIR=\"output\"\n",
    "\n",
    "# Create an output directory\n",
    "mkdir $OUTDIR\n",
    "\n",
    "# Generate pseudolikelihood function ln(p)(q, lambdat) for each BNS event\n",
    "python ../../bin/generate_likelihood.py \\\n",
    "--pefiles $PEDATA0 $PEDATA1 $PEDATA2 \\\n",
    "--outfile ${OUTDIR}/pseudolikelihood.hdf5 \\\n",
    "--qmin 0.125 --lambdatmax 10000 --gridsize 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "OUTDIR=\"output\"\n",
    "# This should be at least 1000 (possibly 10000)\n",
    "NITER=1000\n",
    "\n",
    "# Sample the prior\n",
    "python ../bin/sample_distribution.py \\\n",
    "--infile ${OUTDIR}/pseudolikelihood.hdf5 \\\n",
    "--outfile ${OUTDIR}/prior.hdf5 \\\n",
    "--distribution prior \\\n",
    "--nwalkers 64 --niter $NITER --nthin 1 \\\n",
    "--massknown 1.93 --vsmax 1.1 --qmin 0.125 --mmin 0.5 --mmax 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "OUTDIR=\"output\"\n",
    "# This should be at least 1000 (possibly 10000)\n",
    "NITER=1000\n",
    "\n",
    "# Sample the posterior\n",
    "python ../bin/sample_distribution.py \\\n",
    "--infile ${OUTDIR}/pseudolikelihood.hdf5 \\\n",
    "--outfile ${OUTDIR}/posterior.hdf5 \\\n",
    "--distribution posterior \\\n",
    "--nwalkers 64 --niter $NITER --nthin 1 \\\n",
    "--massknown 1.93 --vsmax 1.1 --qmin 0.125 --mmin 0.5 --mmax 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "OUTDIR=\"output\"\n",
    "# Run the postprocessing script\n",
    "python ../bin/calculate_ns_properties.py \\\n",
    "--priorfile ${OUTDIR}/prior.hdf5 \\\n",
    "--posteriorfile ${OUTDIR}/posterior.hdf5 \\\n",
    "--outfile ${OUTDIR}/ns_properties.hdf5 \\\n",
    "--nburnin 200 --nthin 10 --nsample 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "OUTDIR=\"output\"\n",
    "\n",
    "# Generate output html page\n",
    "python ../bin/generate_eos_output_page.py \\\n",
    "--infile ${OUTDIR}/ns_properties.hdf5 \\\n",
    "--outdir ${OUTDIR}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
